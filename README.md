Нейросеть была взята с сайта Kaggle:

https://www.kaggle.com/code/parthivakilesh/fire-detection/notebook

Использованный датасет:

https://www.kaggle.com/datasets/phylake1337/fire-dataset

Целью было использование набора данных для разработки модели, которая может распознавать изображения пожара.

Данные собирались для обучения модели классификации изображений, содержащих огонь (изображения огня), и изображений, на которых не был изображен огонь, основная задача заключалась в бинарной классификации .
Данные разделены на 2 директории: 
1) fire_images содержит 755 изображений пожара на открытом воздухе, некоторые из которых содержат густой дым, 
2) non-fire_images содержит 244 изображения природы (например, лес, дерево, трава, река, люди, туманный лес, озеро, животное, дорога и водопад).
После загрузки тренировочных данных выполняется преобразование фотографий к формату 196 x 196.

Автор модели с Kaggle по результатам обучения получил следующие результаты : 
accuracy: 0.9613. loss: 0.1009.
val_accuracy: 0.9497. val_loss 0.1790.

В результате проведения различных вариантов тестирования модели, мне удалось добиться улучшения точности и уменьшения потерь. 
Было проведено 7 тестов.

Тест 1.

Входные параметры были взяты те же, что и у автора.

Полученные мной реультаты на тренировочном наборе: accuracy: 0.9490 - loss: 0.1218

Однако, на val_loss и val_accuracy по результату тестирования ≈ 0.116 и 0.959. 

То есть, значительное сокращение потерь и небольшое увеличение точонсти. Далее, буду рассматривать только показатели тестовых наборов, так как они имеют большую значимость.

Тест 2.

Увеличив количество эпох с 5 до 15-ти мы не получили существенных улучшений. Точность модели выросла на 1%, потери также увеличились на 1%. 
Точность особенно значима в задачах классификации, где важен процент правильных ответов.  Поэтому, изменение, скорее положительное.

Тест 3.

В предыдущем тесте наилучшие значения val_loss и val_accuracy были на 11-й эпохе. Значит, предположительно после 11-й начинается переобучение. 
Проведя тестирование с количеством эпох равным 11 были получены лучшие показатели val_loss и val_accuracy:

[0.101124607026577, 0.9748743772506714]

Тест 4.

Поэкспериментируем с размером батчей. Увеличение с 32 до  64 привело к самым низким показателям точности и к самому большому количеству потерь.

[0.1313096582889557, 0.9547738432884216]

Тест 5.

Проверим есть ли закономерность между увеличением размера батчей и ухудшением характеристик. При увеличении размера батчей ещё в 2 раза, характеристики не ухудшились. Модель показала средний результат при размере батча 128.

[0.11930988729000092, 0.9648241400718689]

Тест 6.

Продолжим наблюдать, увеличив размерность батчей до 256. Это в 8 раз больше, чем изначально.
При такой размерности батчей точность чуть ниже средней, однако количество потерь примерно в 2 раза больше как на тестовом, так и на тренировочном наборах данных. 

[0.2293885201215744, 0.9597989916801453]

Размерность batch_Size = 256 точно не подходит для улучшения модели.

Тест 7.

Для подобной модели классификации обычно рекомендуется использовать соотношение около 70-80% тренировочных фотографий и 20-30% тестовых фотографий для эффективного обучения. 
Такое соотношение помогает модели обучаться на достаточном количестве данных, а затем проверить ее эффективность на отдельных тестовых данных. 
Тестовый набор изменим с 20% до 30% и тренировочный с 80% до 70%.
В качестве входных данных(batch_Size, epochs) возьмем те же, что и в 3-ей модели, так как они показали лучший результат.
После изменения соотношения тестовых и тренировочных входных данных показатели val_accuracy и val_loss ухудшились на ≈ 3%.

[0.12966260313987732, 0.9397993087768555]

Значит, соотношение тренировочных и тестовых входных данных 80%/20% - является более подходящим.

Вывод: 

При довольно высоких изначальных показателях, точность модели удалось улучшить на ≈ 3% до 0.974, потери удалось сократить на ≈ 8% до 0.101, увеличив количество эпох до 11-ти. Увеличение размера батчей и изменение процентного соотношения тренировочных и тестовых входных данных не принесло улучшения результатов. Функция потерь и оптимайзер подобраны для модели классификации. Обучение модели стабильно, без резких колебаний в качестве или потерях. Постепенное улучшение показателей как на обучающем, так и на тестовом наборе свидетельствует о качественном процессе обучения.
